{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "shaped-bridge",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "features2 = ['SLHC', 'HST', 'HCT', 'MCV', 'MCH', 'MCHC', 'RDWCV', 'SLTC', 'SLBC', 'FE', 'FERRITIN', 'HBA1', 'HBA2', 'HBE', 'HBF']\n",
    "features = ['SLHC', 'HST', 'HCT', 'MCV', 'MCH', 'MCHC', 'RDWCV', 'SLTC', 'SLBC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dying-entry",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85.0\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(\"../datasets/processed_data.csv\", low_memory=False)\n",
    "df1.PID = df1.PID.astype(str)\n",
    "df1.set_index(\"PID\", inplace=True)\n",
    "feature_df = df1[features]\n",
    "feature_df = feature_df.apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "df1 = df1.loc[feature_df.dropna().index][features2 + ['sheet']]\n",
    "df1 = df1.assign(alpha=0, beta=0)\n",
    "condition = df1.sheet.isin(['alpha', 'fe_alpha', 'alpha_beta'])\n",
    "df1['alpha'] = condition.astype(int)\n",
    "\n",
    "condition = df1.sheet.isin(['beta', 'fe_beta', 'alpha_beta'])\n",
    "df1['beta'] = condition.astype(int)\n",
    "# df1 = df1.assign(sheet='1803')\n",
    "print(df1[df1.sheet == 'normal'].MCV.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "posted-arena",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19108, 18)\n",
      "(1671, 18)\n",
      "(663, 18)\n",
      "(772, 18)\n",
      "(664, 18)\n",
      "(264, 18)\n"
     ]
    }
   ],
   "source": [
    "def get_df(file_path, sheet_type):\n",
    "    df = pd.read_csv(file_path)\n",
    "    df.set_index('PID', inplace=True)\n",
    "\n",
    "    return df.assign(sheet=sheet_type)\n",
    "\n",
    "df2 = get_df(\"../datasets/0504.csv\", '0504')\n",
    "df3 = get_df(\"../datasets/1904.csv\", '1904')\n",
    "df4 = get_df(\"../datasets/2704.csv\", '2704')\n",
    "df5 = get_df(\"../datasets/2804.csv\", '2804')\n",
    "df6 = get_df(\"../datasets/2904.csv\", '2904')\n",
    "\n",
    "df_arr = [df1, df2, df3, df4, df5, df6]\n",
    "for e in df_arr:\n",
    "    print(e.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dependent-intranet",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat(df_arr).to_csv(\"tong_hop1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "local-horizon",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_hc(df):\n",
    "    conditions = (df.alpha + df.beta == 0) & (df.MCV >= 85) &(df.MCH >= 28)\n",
    "    idxes = conditions.index\n",
    "    return conditions.sum(), idxes, conditions\n",
    "\n",
    "def both_ab(df):\n",
    "    conditions = (df.alpha + df.beta == 2)\n",
    "    idxes = conditions.index\n",
    "    return conditions.sum(), idxes, conditions\n",
    "\n",
    "def alpha(df):\n",
    "    conditions = df.alpha == 1\n",
    "    idxes = conditions.index\n",
    "    return conditions.sum(), idxes, conditions\n",
    "\n",
    "def beta(df):\n",
    "    conditions = df.beta == 1\n",
    "    idxes = conditions.index\n",
    "    return conditions.sum(), idxes, conditions\n",
    "\n",
    "def lack_fe(df):\n",
    "    conditions = (~df.FERRITIN.isna()) & (df.FERRITIN < 30)\n",
    "    df_fe = df[conditions]\n",
    "    \n",
    "    alpha_num, alpha_idx, alpha_condition = alpha(df_fe)\n",
    "    beta_num, beta_idx, beta_condition = beta(df_fe)\n",
    "    \n",
    "    print('fe_alpha', alpha_num)\n",
    "    print(\"fe_beta\", beta_num)\n",
    "    \n",
    "    df_fe2 = df_fe[~(alpha_condition | beta_condition)]\n",
    "    \n",
    "    return df_fe2.shape[0], df_fe2.index, conditions\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def statistic(df):\n",
    "    df[features2] =  df[features2].apply(pd.to_numeric, errors='coerce', downcast='float')\n",
    "    normal_num, normal_idx, normal_conditions = normal_hc(df)\n",
    "    \n",
    "    dfa = df[~normal_conditions]\n",
    "    ab_num, ab_idx, ab_conditions = both_ab(dfa)\n",
    "    \n",
    "    dfb = dfa[~ab_conditions]\n",
    "    fe_num, fe_idx, fe_conditions = lack_fe(dfb)\n",
    "    \n",
    "    dfc = dfb[~fe_conditions]\n",
    "    alpha_num, alpha_idx, alpha_condition = alpha(dfc)\n",
    "    beta_num, beta_idx, beta_condition = beta(dfc)\n",
    "    \n",
    "    print('normal', normal_num)\n",
    "    print(\"alpha_beta\", ab_num)\n",
    "    print('normal_fe', fe_num)\n",
    "    print('alpha', alpha_num)\n",
    "    print(\"beta\", beta_num)\n",
    "    \n",
    "    \n",
    "# for df in df_arr:\n",
    "#     print(df.shape)\n",
    "#     statistic(df)\n",
    "#     print(\"----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "colonial-handy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "creative-driving",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23142, 18)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "covered-logic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fe_alpha 775\n",
      "fe_beta 303\n",
      "normal 10164\n",
      "alpha_beta 1855\n",
      "normal_fe 1109\n",
      "alpha 4971\n",
      "beta 2851\n"
     ]
    }
   ],
   "source": [
    "statistic(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "accessory-hungarian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4972, 18), (2851, 18), (2223, 18))"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_normal(df):\n",
    "    conditions = (df.alpha + df.beta == 0) & (df.MCV >= 85) &(df.MCH >= 28)\n",
    "    return df[conditions]\n",
    "\n",
    "\n",
    "def get_alpha_beta(df):\n",
    "    conditions = (df.alpha + df.beta == 2)\n",
    "    return df[conditions]\n",
    "\n",
    "def get_alpha(df):\n",
    "    conditions1 = ~((df.alpha + df.beta == 0) & (df.MCV >= 85) &(df.MCH >= 28))\n",
    "    conditions2 = (df.alpha == 1) & (df.beta == 0)\n",
    "    conditions3 = (~df.FERRITIN.isna()) & (~df.FE.isna()) & (df.FERRITIN < 30)\n",
    "    return df[conditions1 & conditions2 & ~conditions3 ]\n",
    "\n",
    "def get_beta(df):\n",
    "    conditions1 = ~((df.alpha + df.beta == 0) & (df.MCV >= 85) &(df.MCH >= 28))\n",
    "    conditions2 = (df.alpha == 0) & (df.beta == 1)\n",
    "    conditions3 = (~df.FERRITIN.isna()) & (~df.FE.isna()) & (df.FERRITIN < 30)\n",
    "    return df[conditions1 & conditions2 & ~conditions3 ]\n",
    "    \n",
    "\n",
    "def get_normal_fe(df):\n",
    "    conditions = (~df.FERRITIN.isna()) & (~df.FE.isna()) & (df.FERRITIN < 30) & (df.alpha + df.beta == 0)\n",
    "    print(df.alpha.unique(), df.beta.unique())\n",
    "    return df[conditions]\n",
    "\n",
    "def negative_unnormal(df):\n",
    "    conditions1 = ~((df.MCV >= 85) &(df.MCH >= 28))\n",
    "    conditions2 = df.alpha + df.beta == 0\n",
    "    return df[conditions1 & conditions2]\n",
    "\n",
    "get_alpha(df).shape, get_beta(df).shape, negative_unnormal(df).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "allied-badge",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SLHC</th>\n",
       "      <th>HST</th>\n",
       "      <th>HCT</th>\n",
       "      <th>MCV</th>\n",
       "      <th>MCH</th>\n",
       "      <th>MCHC</th>\n",
       "      <th>RDWCV</th>\n",
       "      <th>SLTC</th>\n",
       "      <th>SLBC</th>\n",
       "      <th>FE</th>\n",
       "      <th>FERRITIN</th>\n",
       "      <th>HBA1</th>\n",
       "      <th>HBA2</th>\n",
       "      <th>HBE</th>\n",
       "      <th>HBF</th>\n",
       "      <th>sheet</th>\n",
       "      <th>alpha</th>\n",
       "      <th>beta</th>\n",
       "      <th>thalas</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97500602</th>\n",
       "      <td>3.02</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.293</td>\n",
       "      <td>97.099998</td>\n",
       "      <td>26.900000</td>\n",
       "      <td>277.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>195.0</td>\n",
       "      <td>7.55</td>\n",
       "      <td>28.0</td>\n",
       "      <td>67.099998</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97220957</th>\n",
       "      <td>4.11</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.399</td>\n",
       "      <td>97.099998</td>\n",
       "      <td>29.900000</td>\n",
       "      <td>308.0</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>214.0</td>\n",
       "      <td>9.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>98.300003</td>\n",
       "      <td>1.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97231143</th>\n",
       "      <td>5.21</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.495</td>\n",
       "      <td>94.900002</td>\n",
       "      <td>27.100000</td>\n",
       "      <td>286.0</td>\n",
       "      <td>13.500000</td>\n",
       "      <td>339.0</td>\n",
       "      <td>6.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.800003</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97221041</th>\n",
       "      <td>4.42</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.418</td>\n",
       "      <td>94.500000</td>\n",
       "      <td>30.200001</td>\n",
       "      <td>319.0</td>\n",
       "      <td>14.100000</td>\n",
       "      <td>165.0</td>\n",
       "      <td>8.13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.800003</td>\n",
       "      <td>2.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97220964</th>\n",
       "      <td>4.91</td>\n",
       "      <td>146.0</td>\n",
       "      <td>0.463</td>\n",
       "      <td>94.300003</td>\n",
       "      <td>29.700001</td>\n",
       "      <td>315.0</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>270.0</td>\n",
       "      <td>8.18</td>\n",
       "      <td>19.6</td>\n",
       "      <td>1202.099976</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>alpha</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038717</th>\n",
       "      <td>4.04</td>\n",
       "      <td>107.0</td>\n",
       "      <td>0.341</td>\n",
       "      <td>84.500000</td>\n",
       "      <td>26.500000</td>\n",
       "      <td>314.0</td>\n",
       "      <td>13.400000</td>\n",
       "      <td>267.0</td>\n",
       "      <td>5.34</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97.699997</td>\n",
       "      <td>2.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15032051</th>\n",
       "      <td>5.26</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>82.599998</td>\n",
       "      <td>26.100000</td>\n",
       "      <td>316.0</td>\n",
       "      <td>15.200000</td>\n",
       "      <td>177.0</td>\n",
       "      <td>16.65</td>\n",
       "      <td>12.5</td>\n",
       "      <td>353.100006</td>\n",
       "      <td>96.900002</td>\n",
       "      <td>3.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15030562</th>\n",
       "      <td>4.45</td>\n",
       "      <td>139.0</td>\n",
       "      <td>0.420</td>\n",
       "      <td>94.199997</td>\n",
       "      <td>31.100000</td>\n",
       "      <td>330.0</td>\n",
       "      <td>13.600000</td>\n",
       "      <td>273.0</td>\n",
       "      <td>4.36</td>\n",
       "      <td>15.0</td>\n",
       "      <td>98.000000</td>\n",
       "      <td>97.500000</td>\n",
       "      <td>2.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2904</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038277</th>\n",
       "      <td>4.32</td>\n",
       "      <td>88.0</td>\n",
       "      <td>0.307</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>20.500000</td>\n",
       "      <td>288.0</td>\n",
       "      <td>19.600000</td>\n",
       "      <td>321.0</td>\n",
       "      <td>7.66</td>\n",
       "      <td>13.5</td>\n",
       "      <td>1406.599976</td>\n",
       "      <td>84.800003</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15026107</th>\n",
       "      <td>5.37</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.330</td>\n",
       "      <td>61.500000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>315.0</td>\n",
       "      <td>16.799999</td>\n",
       "      <td>233.0</td>\n",
       "      <td>10.71</td>\n",
       "      <td>2.9</td>\n",
       "      <td>72.199997</td>\n",
       "      <td>97.900002</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2904</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23142 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          SLHC    HST    HCT        MCV        MCH   MCHC      RDWCV   SLTC  \\\n",
       "PID                                                                           \n",
       "97500602  3.02   81.0  0.293  97.099998  26.900000  277.0  17.000000  195.0   \n",
       "97220957  4.11  123.0  0.399  97.099998  29.900000  308.0  13.600000  214.0   \n",
       "97231143  5.21  141.0  0.495  94.900002  27.100000  286.0  13.500000  339.0   \n",
       "97221041  4.42  133.0  0.418  94.500000  30.200001  319.0  14.100000  165.0   \n",
       "97220964  4.91  146.0  0.463  94.300003  29.700001  315.0  14.200000  270.0   \n",
       "...        ...    ...    ...        ...        ...    ...        ...    ...   \n",
       "15038717  4.04  107.0  0.341  84.500000  26.500000  314.0  13.400000  267.0   \n",
       "15032051  5.26  138.0  0.435  82.599998  26.100000  316.0  15.200000  177.0   \n",
       "15030562  4.45  139.0  0.420  94.199997  31.100000  330.0  13.600000  273.0   \n",
       "15038277  4.32   88.0  0.307  71.000000  20.500000  288.0  19.600000  321.0   \n",
       "15026107  5.37  104.0  0.330  61.500000  19.400000  315.0  16.799999  233.0   \n",
       "\n",
       "           SLBC    FE     FERRITIN       HBA1  HBA2  HBE  HBF  sheet  alpha  \\\n",
       "PID                                                                           \n",
       "97500602   7.55  28.0    67.099998  96.000000   1.0  NaN  NaN  alpha      1   \n",
       "97220957   9.56   NaN          NaN  98.300003   1.7  NaN  NaN  alpha      1   \n",
       "97231143   6.54   NaN          NaN  97.800003   2.2  NaN  NaN  alpha      1   \n",
       "97221041   8.13   NaN          NaN  97.800003   2.2  NaN  NaN  alpha      1   \n",
       "97220964   8.18  19.6  1202.099976  97.900002   2.1  NaN  NaN  alpha      1   \n",
       "...         ...   ...          ...        ...   ...  ...  ...    ...    ...   \n",
       "15038717   5.34  56.0          NaN  97.699997   2.3  NaN  NaN   2904      1   \n",
       "15032051  16.65  12.5   353.100006  96.900002   3.1  NaN  NaN   2904      0   \n",
       "15030562   4.36  15.0    98.000000  97.500000   2.5  NaN  NaN   2904      0   \n",
       "15038277   7.66  13.5  1406.599976  84.800003   2.1  NaN  NaN   2904      1   \n",
       "15026107  10.71   2.9    72.199997  97.900002   2.1  NaN  NaN   2904      1   \n",
       "\n",
       "          beta  thalas  \n",
       "PID                     \n",
       "97500602     0       1  \n",
       "97220957     0       1  \n",
       "97231143     0       1  \n",
       "97221041     0       1  \n",
       "97220964     0       1  \n",
       "...        ...     ...  \n",
       "15038717     0       1  \n",
       "15032051     0       0  \n",
       "15030562     0       0  \n",
       "15038277     0       1  \n",
       "15026107     0       1  \n",
       "\n",
       "[23142 rows x 19 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.assign(thalas = (df.alpha + df.beta > 0).astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "interracial-toddler",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, RandomForestRegressor\n",
    "\n",
    "numerical_columns = [\"SLHC\",\"HST\",\"HCT\",\"MCV\",\"MCH\",\"MCHC\",\"RDWCV\",\"SLTC\",\"SLBC\", \"FERRITIN\",\"FE\"]\n",
    "\n",
    "def fit_model(model, df):\n",
    "#     global numerical_columns\n",
    "    \n",
    "    df[numerical_columns].dropna()\n",
    "    print(df.shape, df[numerical_columns].dropna().shape)\n",
    "    X = df[numerical_columns]\n",
    "    y = df['thalas']\n",
    "\n",
    "    # model.partial_fit(X, y)\n",
    "    model.fit(X, y)\n",
    "    \n",
    "\n",
    "def evaluate(model, df, desc=''):\n",
    "#     global numerical_columns\n",
    "    \n",
    "    X = df[numerical_columns]\n",
    "    y = df['thalas']\n",
    "    \n",
    "    preds = np.array(model.predict(X))\n",
    "    print('---------------------------------------------------')\n",
    "    print(f\"evaluation results {desc}:\\n\")\n",
    "    print(classification_report(y, np.where(preds>=0.5, 1, 0)))\n",
    "    print('---------------------------------------------------')\n",
    "\n",
    "    # mask = preds != y\n",
    "    mask = (0.3 <= preds) & (preds <= 0.7)\n",
    "    print(sum(mask))\n",
    "\n",
    "    features_df = df[mask][numerical_columns].reset_index(drop=True)\n",
    "    labels = preds[mask]\n",
    "    labels = np.where(labels>=0.5, 1, 0)\n",
    "    # print(labels)\n",
    "    new_df = pd.concat([features_df, pd.DataFrame({'thalas': labels})], axis=1)\n",
    "\n",
    "    return new_df, df[preds == y].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "first-lingerie",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = RandomForestRegressor(n_estimators = 100, random_state=42,n_jobs=8)\n",
    "# model = xgb.XGBClassifier(learning_rate=0.1, max_depth=10, n_estimators=100, n_jobs=-1, random_state=42,use_label_encoder=False, objective=\"binary:logistic\")\n",
    "model = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "contained-pride",
   "metadata": {},
   "outputs": [],
   "source": [
    "# beta_df = get_alpha(df)\n",
    "beta_df = get_beta(df)\n",
    "alpha_df = negative_unnormal(df)\n",
    "\n",
    "alpha_df.shape, beta_df.shape\n",
    "\n",
    "alpha_df = alpha_df.assign(thalas=0)\n",
    "beta_df = beta_df.assign(thalas=1)\n",
    "\n",
    "main_df = pd.concat([alpha_df, beta_df])\n",
    "dropted_df = main_df.loc[main_df[numerical_columns].dropna().index]\n",
    "dropted_df = dropted_df.loc[dropted_df[numerical_columns].dropna().index]\n",
    "train_df, test_df = train_test_split(dropted_df, test_size=0.2, stratify=dropted_df.thalas)\n",
    "\n",
    "# alpha_df.shape, beta_df.shape, main_df.shape, dropted_df.shape, dropted_df[numerical_columns].dropna().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "general-acrobat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3860, 19) (3787, 11)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-162-a050c5d9850b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# train_df.info()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-149-139aaaa2f856>\u001b[0m in \u001b[0;36mfit_model\u001b[0;34m(model, df)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# model.partial_fit(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m         \"\"\"\n\u001b[0;32m--> 207\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    815\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    664\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "fit_model(model, train_df)\n",
    "# train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "intense-crest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------\n",
      "evaluation results :\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.80      0.85       340\n",
      "           1       0.84      0.93      0.88       382\n",
      "\n",
      "    accuracy                           0.87       722\n",
      "   macro avg       0.88      0.87      0.87       722\n",
      "weighted avg       0.88      0.87      0.87       722\n",
      "\n",
      "---------------------------------------------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "_ = evaluate(model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worthy-qualification",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
